# MATD3 for Berth Allocation with Shore Power Coordination

å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMATD3ï¼‰åœ¨è¿ç»­æ³Šä½åˆ†é…ä¸å²¸ç”µååŒä¼˜åŒ–ä¸­çš„åº”ç”¨ã€‚

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†åŸºäºMATD3ï¼ˆMulti-Agent Twin Delayed Deep Deterministic Policy Gradientï¼‰ç®—æ³•çš„è‡ªåŠ¨åŒ–é›†è£…ç®±ç å¤´æ³Šä½åˆ†é…ä¸å²¸ç”µååŒä¼˜åŒ–ç³»ç»Ÿã€‚

### æ ¸å¿ƒç‰¹æ€§

- **POMDPå»ºæ¨¡**: éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹
- **CTDEæ¶æ„**: é›†ä¸­è®­ç»ƒã€åˆ†æ•£æ‰§è¡Œ
- **è¿ç»­åŠ¨ä½œç©ºé—´**: æ³Šä½ä½ç½®ã€ç­‰å¾…æ—¶é—´ã€å²¸ç”µä½¿ç”¨æ¦‚ç‡
- **å¤šç›®æ ‡ä¼˜åŒ–**: æ³Šä½åˆ©ç”¨ç‡ã€èˆ¹èˆ¶ç­‰å¾…æ—¶é—´ã€ç¢³æ’æ”¾
- **æ”¹è¿›è®¾è®¡**: åŸºäºè®ºæ–‡è¯„å®¡æ„è§çš„å¤šé¡¹æ”¹è¿›

### è®ºæ–‡å¯¹åº”æ”¹è¿›

| è¯„å®¡é—®é¢˜ | æ”¹è¿›å®ç° |
|---------|---------|
| çŠ¶æ€å™ªå£°æ··æ·†æ¢ç´¢æ¦‚å¿µ | 17ç»´è§‚æµ‹ï¼ˆç§»é™¤å™ªå£°ç»´åº¦ï¼‰ï¼Œä»…åœ¨åŠ¨ä½œå±‚åŠ å™ªå£° |
| åˆ†æ•£é æ³Šå¥–åŠ±ä¸åˆç† | åŸºäºé‚»è¿‘èˆ¹èˆ¶æ‹¥æŒ¤åº¦çš„å‡¸æƒ©ç½šè®¾è®¡ |
| èˆ¹èˆ¶ç”Ÿæˆè¿‡äºç®€å• | éé½æ¬¡æ³Šæ¾è¿‡ç¨‹ + å¤šå³°åˆ†å¸ƒ |
| ç¼ºå°‘å¥–åŠ±æƒé‡æ¶ˆè | æä¾›å®Œæ•´çš„æ•æ„Ÿæ€§åˆ†ææ¡†æ¶ |
| å¯è§†åŒ–ä¸è¶³ | å²¸ç”µè´Ÿè½½æ›²çº¿ã€æ³Šä½çƒ­åŠ›å›¾ã€å†²çªæ£€æµ‹ |

## é¡¹ç›®ç»“æ„

```
MARL-task/
â”œâ”€â”€ config/                      # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ default_config.yaml     # é»˜è®¤é…ç½®
â”œâ”€â”€ environment/                 # ç¯å¢ƒæ¨¡å—
â”‚   â”œâ”€â”€ vessel.py               # èˆ¹èˆ¶ç±»ä¸ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ shore_power.py          # å²¸ç”µç®¡ç†å™¨
â”‚   â””â”€â”€ berth_env.py            # æ³Šä½ç¯å¢ƒ
â”œâ”€â”€ agents/                      # æ™ºèƒ½ä½“æ¨¡å—
â”‚   â”œâ”€â”€ networks.py             # ç¥ç»ç½‘ç»œï¼ˆActor/Criticï¼‰
â”‚   â”œâ”€â”€ replay_buffer.py        # ç»éªŒå›æ”¾æ± 
â”‚   â””â”€â”€ matd3.py                # MATD3ç®—æ³•
â”œâ”€â”€ rewards/                     # å¥–åŠ±å‡½æ•°
â”‚   â””â”€â”€ reward_calculator.py    # å¥–åŠ±è®¡ç®—å™¨
â”œâ”€â”€ training/                    # è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ trainer.py              # è®­ç»ƒå™¨
â”‚   â””â”€â”€ evaluator.py            # è¯„ä¼°å™¨
â”œâ”€â”€ visualization/               # å¯è§†åŒ–ï¼ˆå¾…å®ç°ï¼‰
â”œâ”€â”€ data/                        # æ•°æ®ç›®å½•
â”œâ”€â”€ results/                     # ç»“æœç›®å½•
â”‚   â”œâ”€â”€ models/                 # æ¨¡å‹ä¿å­˜
â”‚   â”œâ”€â”€ logs/                   # æ—¥å¿—
â”‚   â””â”€â”€ figures/                # å›¾è¡¨
â”œâ”€â”€ main.py                      # ä¸»å…¥å£
â”œâ”€â”€ requirements.txt             # ä¾èµ–
â””â”€â”€ README.md                    # æœ¬æ–‡æ¡£
```

## å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python >= 3.8
- PyTorch >= 2.0.0

### å®‰è£…æ­¥éª¤

1. å…‹éš†ä»“åº“ï¼ˆæˆ–ä½¿ç”¨æœ¬åœ°ç›®å½•ï¼‰:
```bash
cd /Users/duan/mac-miclsirr/Sensors-models/MARL-task
```

2. å®‰è£…ä¾èµ–:
```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹æ³•

### è®­ç»ƒ

ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒMATD3æ™ºèƒ½ä½“ï¼š

```bash
python main.py --mode train --config config/default_config.yaml
```

æŒ‡å®šè®¾å¤‡å’Œéšæœºç§å­ï¼š

```bash
python main.py --mode train --config config/default_config.yaml \
  --device cuda --seed 42
```

### è¯„ä¼°

è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼š

```bash
python main.py --mode eval --model results/models/best_model.pth \
  --config config/default_config.yaml
```

### é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config/default_config.yaml` ä»¥ä¿®æ”¹ï¼š

- ç¯å¢ƒå‚æ•°ï¼ˆæ³Šä½é•¿åº¦ã€èˆ¹èˆ¶æ•°é‡ç­‰ï¼‰
- å¥–åŠ±æƒé‡ï¼ˆc1-c8ï¼‰
- ç½‘ç»œç»“æ„
- è®­ç»ƒè¶…å‚æ•°

## ğŸ“š å®Œæ•´æ–‡æ¡£

æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£è¯·è®¿é—®ï¼š**[docs/README.md](docs/README.md)**

æ ¸å¿ƒæ–‡æ¡£ï¼š
- **[RLlibå®Œæ•´æŒ‡å—](docs/RLLIB_COMPLETE_GUIDE.md)** - RLlibæ¡†æ¶ã€ç¯å¢ƒå®ç°ã€è®­ç»ƒé…ç½®ã€å¹¶è¡Œä¼˜åŒ–ã€åˆ†å¸ƒå¼è®­ç»ƒ
- **[ç®—æ³•è®¾è®¡](docs/ALGORITHM_DESIGN.md)** - é—®é¢˜å»ºæ¨¡ã€ç¯å¢ƒè®¾è®¡ã€å¥–åŠ±å‡½æ•°ã€ç®—æ³•å®ç°ã€æ”¹è¿›ä¼˜åŒ–
- **[ç³»ç»Ÿæ¶æ„](docs/SYSTEM_ARCHITECTURE.md)** - æ•´ä½“æ¶æ„ã€æ ¸å¿ƒæ¨¡å—ã€æ•°æ®æµç¨‹ã€éƒ¨ç½²æ¶æ„ã€å¼€å‘æŒ‡å—

## æ ¸å¿ƒæ¨¡å—è¯´æ˜

### 1. ç¯å¢ƒæ¨¡å— (environment/)

#### æ³Šä½ç¯å¢ƒ (BerthAllocationEnv)

- **è§‚æµ‹ç©ºé—´**: 17ç»´å±€éƒ¨ç‰¹å¾
  - é™æ€: èˆ¹é•¿ã€åˆ°æ¸¯æ—¶é—´ã€ä¼˜å…ˆçº§ã€å²¸ç”µèƒ½åŠ›
  - åŠ¨æ€: å½“å‰æ—¶é—´ã€å·²ç­‰å¾…æ—¶é—´ã€æ“ä½œæ—¶é—´
  - å²¸ç”µ: 5æ®µä½¿ç”¨ç‡ + æ€»ä½¿ç”¨ç‡
  - æ³Šä½: å·¦å³é‚»è¿‘è·ç¦»ã€å¯ç”¨ç©ºé—´

- **åŠ¨ä½œç©ºé—´**: 3ç»´è¿ç»­åŠ¨ä½œ [0, 1]
  - ä½ç½®: é æ³Šä½ç½®ï¼ˆå½’ä¸€åŒ–ï¼‰
  - æ—¶é—´: ç­‰å¾…æ—¶é•¿ï¼ˆå½’ä¸€åŒ–ï¼‰
  - æ¦‚ç‡: å²¸ç”µä½¿ç”¨æ¦‚ç‡

#### èˆ¹èˆ¶ç”Ÿæˆå™¨ (VesselGenerator)

æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
- **realistic**: éé½æ¬¡æ³Šæ¾åˆ°æ¸¯ + å¤šå³°èˆ¹é•¿åˆ†å¸ƒ
- **simple**: ç®€å•å‡åŒ€åˆ†å¸ƒï¼ˆåŸºçº¿ï¼‰

### 2. æ™ºèƒ½ä½“æ¨¡å— (agents/)

#### MATD3ç®—æ³•

- **Actor**: æ¯ä¸ªæ™ºèƒ½ä½“ç‹¬ç«‹ç­–ç•¥ç½‘ç»œ
- **Critic**: å…±äº«åŒCriticç½‘ç»œï¼ˆé›†ä¸­ä»·å€¼ä¼°è®¡ï¼‰
- **å…³é”®æœºåˆ¶**:
  - åŒQå­¦ä¹ æŠ‘åˆ¶é«˜ä¼°
  - å»¶è¿Ÿç­–ç•¥æ›´æ–°
  - ç›®æ ‡ç­–ç•¥å¹³æ»‘
  - åˆ†ç»´åº¦æ¢ç´¢å™ªå£°

### 3. å¥–åŠ±å‡½æ•° (rewards/)

å¤šç›®æ ‡å¥–åŠ±è®¾è®¡ï¼š

```python
reward = c1 * base_reward              # åŸºç¡€æ­£å¥–åŠ±
       - c2 * waiting_penalty          # ç­‰å¾…æƒ©ç½š
       - c3 * emission_penalty         # ç¢³æ’æ”¾æƒ©ç½š
       + c4 * shore_power_bonus        # å²¸ç”µå¥–åŠ±
       + c5 * utilization_reward       # åˆ©ç”¨ç‡å¥–åŠ±
       + c6 * spacing_reward           # åˆ†æ•£é æ³Šå¥–åŠ±ï¼ˆæ”¹è¿›ï¼‰
```

**æ”¹è¿›ç‚¹**: spacing_reward åŸºäºé‚»è¿‘æ‹¥æŒ¤åº¦ï¼Œè€Œéå²¸çº¿ä¸­å¿ƒè·ç¦»

## å®éªŒé…ç½®

### é»˜è®¤å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|-----|
| æ³Šä½é•¿åº¦ | 2000m | è¿ç»­å²¸çº¿é•¿åº¦ |
| è§„åˆ’å‘¨æœŸ | 7å¤© | è§„åˆ’æ—¶é—´çª— |
| æœ€å¤§èˆ¹èˆ¶æ•° | 20 | æ¯å›åˆèˆ¹èˆ¶æ•° |
| Actorå­¦ä¹ ç‡ | 1e-4 | ç­–ç•¥ç½‘ç»œå­¦ä¹ ç‡ |
| Criticå­¦ä¹ ç‡ | 1e-3 | ä»·å€¼ç½‘ç»œå­¦ä¹ ç‡ |
| æŠ˜æ‰£å› å­ | 0.99 | Î³ |
| è½¯æ›´æ–°ç³»æ•° | 0.005 | Ï„ |
| ç­–ç•¥å»¶è¿Ÿ | 2 | å»¶è¿Ÿæ›´æ–°æ­¥æ•° |

### è®­ç»ƒå»ºè®®

1. **åˆå§‹è®­ç»ƒ**: 5000 episodesï¼Œè¯„ä¼°é—´éš” 100
2. **æ‰¹é‡å¤§å°**: 256ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰
3. **ç»éªŒæ± **: 1M transitions
4. **è®¾å¤‡**: å»ºè®®ä½¿ç”¨GPUåŠ é€Ÿ

## è¯„ä¼°æŒ‡æ ‡

- **berth_utilization**: æ³Šä½åˆ©ç”¨ç‡ï¼ˆæ—¶ç©ºå ç”¨ç‡ï¼‰
- **avg_waiting_time**: å¹³å‡ç­‰å¾…æ—¶é—´ï¼ˆå°æ—¶ï¼‰
- **total_emissions**: æ€»ç¢³æ’æ”¾ï¼ˆkg CO2ï¼‰
- **shore_power_usage_rate**: å²¸ç”µä½¿ç”¨ç‡
- **avg_inference_time**: å¹³å‡æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰

## æŠ€æœ¯ç»†èŠ‚

### CTDEæ¶æ„

```
è®­ç»ƒæ—¶:
  Actor_i(obs_i) -> action_i
  Critic(global_state, all_actions) -> Q-value

æ‰§è¡Œæ—¶:
  Actor_i(obs_i) -> action_i  (åˆ†æ•£æ‰§è¡Œ)
```

### åŒCriticæœºåˆ¶

```python
target_q1 = Critic1_target(s', a')
target_q2 = Critic2_target(s', a')
target_q = min(target_q1, target_q2)  # æŠ‘åˆ¶é«˜ä¼°
```

### æ¢ç´¢å™ªå£°è®¾è®¡

```python
# ä½ç½®: é«˜æ–¯å™ªå£°
position += N(0, Ïƒ_pos)

# æ—¶é—´: é«˜æ–¯å™ªå£°
time += N(0, Ïƒ_time)

# å²¸ç”µæ¦‚ç‡: å‡åŒ€å™ªå£°
prob += U(-Ïƒ_prob, Ïƒ_prob)
```

## æ•…éšœæ’é™¤

é‡åˆ°é—®é¢˜ï¼ŸæŸ¥çœ‹ **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** è·å–è§£å†³æ–¹æ¡ˆã€‚

å¸¸è§é—®é¢˜ï¼š
- å¯åŠ¨å¤±è´¥ - ä¾èµ–æœªå®‰è£…
- ç«¯å£è¢«å ç”¨
- Condaç¯å¢ƒé—®é¢˜
- TensorBoardæ— æ•°æ®
- Webç•Œé¢æ— æ³•è¿æ¥

## å¸¸è§ä»»åŠ¡

### è®­ç»ƒæ¨¡å‹

```bash
python main.py --mode train --config config/default_config.yaml
```

### åŠ è½½çœŸå®æ•°æ®

```python
from environment import VesselGenerator

generator = VesselGenerator(config)
vessels = generator.load_from_csv('data/real_world/vessels.csv')
observations, _ = env.reset(options={'vessels': vessels})
```

### ä¿®æ”¹é…ç½®

ç¼–è¾‘ `config/default_config.yaml` è°ƒæ•´å‚æ•°

## å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨åŸå§‹è®ºæ–‡ï¼š

```bibtex
@article{your_paper_2025,
  title={Multi-Agent Reinforcement Learning for Berth Allocation
         with Shore Power Coordination},
  author={Your Name},
  journal={Journal Name},
  year={2025}
}
```

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

- é—®é¢˜åé¦ˆ: [GitHub Issues](é“¾æ¥)
- é‚®ç®±: your.email@example.com

## å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨ç®¡ç†è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# æŸ¥çœ‹å¸®åŠ©
./manage.sh help

# æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’Œä¾èµ–
./manage.sh check

# å¿«é€Ÿæµ‹è¯•ç¯å¢ƒ
./manage.sh test

# ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
./manage.sh start
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’ŒPythonä¾èµ–
- âœ… å¯åŠ¨åç«¯ (Port 8000)
- âœ… å¯åŠ¨å‰ç«¯ (Port 3000)
- âœ… å¯åŠ¨TensorBoard (Port 6006)

### ç®¡ç†å‘½ä»¤

```bash
# é¡¹ç›®ç®¡ç†
./manage.sh check          # æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’Œä¾èµ–
./manage.sh test           # å¿«é€Ÿæµ‹è¯•ç¯å¢ƒ
./manage.sh archive        # å½’æ¡£æ—§ä»£ç  (EPyMARL/MATD3)
./manage.sh clean          # æ¸…ç†æ—¥å¿—å’Œä¸´æ—¶æ–‡ä»¶

# è®­ç»ƒç®¡ç†
./manage.sh train          # å¯åŠ¨RLlibè®­ç»ƒ
./manage.sh tensorboard    # å¯åŠ¨TensorBoardç›‘æ§

# æœåŠ¡ç®¡ç†
./manage.sh backend        # å¯åŠ¨åç«¯æœåŠ¡ (Port 8000)
./manage.sh frontend       # å¯åŠ¨å‰ç«¯æœåŠ¡ (Port 3000)
./manage.sh start          # å¯åŠ¨æ‰€æœ‰æœåŠ¡
./manage.sh stop           # åœæ­¢æ‰€æœ‰æœåŠ¡

# æ—¥å¿—ç®¡ç†
./manage.sh logs training  # æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
./manage.sh logs backend   # æŸ¥çœ‹åç«¯æ—¥å¿—
./manage.sh logs testing   # æŸ¥çœ‹æµ‹è¯•æ—¥å¿—
```

### è®¿é—®ç³»ç»Ÿ

å¯åŠ¨åè®¿é—®ï¼š
- **Webç•Œé¢**: http://localhost:3000/index.html
- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **TensorBoard**: http://localhost:6006

### Webç•Œé¢ä½¿ç”¨

1. é…ç½®ä»»åŠ¡å‚æ•°ï¼ˆèˆ¹åªæ•°é‡ã€è®¡åˆ’çª—å£ç­‰ï¼‰
2. ç‚¹å‡»"Generate Task"ç”Ÿæˆä»»åŠ¡
3. é€‰æ‹©ç®—æ³•ï¼ˆMATD3/Greedy/FCFSï¼‰
4. ç‚¹å‡»"Run Algorithm"è¿è¡Œ
5. æŸ¥çœ‹å¯è§†åŒ–ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

## æ›´æ–°æ—¥å¿—

### v2.1 (2025-10-28)

- âœ… **ç»Ÿä¸€ç®¡ç†è„šæœ¬** - manage.shæ›¿ä»£11ä¸ªç‹¬ç«‹è„šæœ¬
- âœ… **RLlibæ¡†æ¶** - å®Œæ•´è¿ç§»åˆ°RLlib 2.50.1
- âœ… **æ–‡æ¡£æ•´åˆ** - 3ä¸ªæ ¸å¿ƒæ–‡æ¡£ï¼ˆRLlib/ç®—æ³•/æ¶æ„ï¼‰
- âœ… **å½’æ¡£æ—§æ¡†æ¶** - EPyMARLå’ŒMATD3å·²å½’æ¡£
- âœ… **è‡ªåŠ¨èµ„æºä¼˜åŒ–** - rllib_train_advanced.py

### v2.0 (2025-01-26)

- âœ… **Webå¯è§†åŒ–ç³»ç»Ÿ** - å‰åç«¯å®Œæ•´å®ç°
- âœ… **TensorBoardæ—¥å¿—** - è®­ç»ƒå®æ—¶å¯è§†åŒ–
- âœ… **Condaç¯å¢ƒæ”¯æŒ** - è‡ªåŠ¨ç¯å¢ƒç®¡ç†
- âœ… **ç»“æ„åŒ–æ—¥å¿—** - JSON + æ–‡æœ¬åŒé‡æ—¥å¿—

### v1.0 (2025-10-25)

- âœ… å®Œæ•´MATD3å®ç°
- âœ… è¿ç»­æ³Šä½ä¸å²¸ç”µååŒç¯å¢ƒ
- âœ… æ”¹è¿›çš„å¥–åŠ±å‡½æ•°ï¼ˆåŸºäºè¯„å®¡æ„è§ï¼‰
- âœ… çœŸå®èˆ¹èˆ¶ç”Ÿæˆï¼ˆéé½æ¬¡æ³Šæ¾ï¼‰
- âœ… è®­ç»ƒä¸è¯„ä¼°æ¡†æ¶

## è‡´è°¢

æ„Ÿè°¢è®ºæ–‡è¯„å®¡ä¸“å®¶çš„å®è´µæ„è§å’Œå»ºè®®ã€‚
