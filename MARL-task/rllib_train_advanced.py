#!/usr/bin/env python3
"""
RLlibé«˜çº§è®­ç»ƒè„šæœ¬ - å¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬
æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒã€GPUåŠ é€Ÿã€æ€§èƒ½ç›‘æ§
"""

import argparse
import os
import sys
import time
import multiprocessing
from datetime import datetime
from typing import Dict, Optional

import ray
from ray import tune
from ray.rllib.algorithms.sac import SACConfig
from ray.rllib.algorithms.ppo import PPOConfig
from ray.rllib.algorithms.appo import APPOConfig
from ray.tune.registry import register_env
from ray.tune.logger import pretty_print

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from rllib_env.berth_allocation_env import BerthAllocationMultiAgentEnv


def register_berth_env():
    """æ³¨å†Œè‡ªå®šä¹‰ç¯å¢ƒ"""
    def env_creator(env_config):
        return BerthAllocationMultiAgentEnv(env_config)

    register_env("berth_allocation", env_creator)


def get_optimal_resources():
    """
    è‡ªåŠ¨æ£€æµ‹å¹¶è¿”å›æœ€ä¼˜èµ„æºé…ç½®

    Returns:
        dict: èµ„æºé…ç½®
    """
    num_cpus = multiprocessing.cpu_count()

    try:
        import torch
        num_gpus = torch.cuda.device_count()
        gpu_available = torch.cuda.is_available()
    except:
        num_gpus = 0
        gpu_available = False

    # è®¡ç®—æœ€ä¼˜workeræ•°é‡
    if num_gpus > 0:
        # æœ‰GPU: workerä¸“æ³¨é‡‡æ ·,learnerç”¨GPU
        num_workers = min(num_cpus - 2, num_gpus * 8)
    else:
        # æ— GPU: å‡å°‘workeré¿å…ç«äº‰
        num_workers = max(2, num_cpus // 2)

    return {
        "num_cpus": num_cpus,
        "num_gpus": num_gpus,
        "gpu_available": gpu_available,
        "recommended_workers": num_workers,
    }


def create_training_config(
    algo_name: str,
    env_config: Dict,
    num_gpus: int = 0,
    num_workers: int = 2,
    distributed: bool = False,
    optimize_for: str = "speed"  # "speed" or "quality"
) -> object:
    """
    åˆ›å»ºè®­ç»ƒé…ç½®

    Args:
        algo_name: ç®—æ³•åç§°
        env_config: ç¯å¢ƒé…ç½®
        num_gpus: GPUæ•°é‡
        num_workers: Workeræ•°é‡
        distributed: æ˜¯å¦åˆ†å¸ƒå¼è®­ç»ƒ
        optimize_for: ä¼˜åŒ–ç›®æ ‡ ("speed"æˆ–"quality")

    Returns:
        é…ç½®å¯¹è±¡
    """

    # é€‰æ‹©ç®—æ³•
    if algo_name.upper() == "SAC":
        config = SACConfig()
    elif algo_name.upper() == "PPO":
        config = PPOConfig()
    elif algo_name.upper() == "APPO":
        config = APPOConfig()
    else:
        raise ValueError(f"Unsupported algorithm: {algo_name}")

    # ç¯å¢ƒé…ç½®
    config.environment(
        env="berth_allocation",
        env_config=env_config,
    )

    # æ¡†æ¶é…ç½®
    config.framework("torch")

    # èµ„æºé…ç½®
    if distributed:
        # åˆ†å¸ƒå¼é…ç½®
        config.resources(
            num_gpus=num_gpus,
            num_cpus_for_driver=min(8, multiprocessing.cpu_count() // 4),
        )
    else:
        # å•æœºé…ç½®
        config.resources(
            num_gpus=num_gpus,
            num_cpus_for_driver=2,
        )

    # Rollouté…ç½® - æ ¹æ®ä¼˜åŒ–ç›®æ ‡è°ƒæ•´
    if optimize_for == "speed":
        # é€Ÿåº¦ä¼˜å…ˆ: æ›´å¤šworker,æ›´é•¿fragment
        config.rollouts(
            num_rollout_workers=num_workers,
            num_envs_per_worker=2,
            rollout_fragment_length=1000,
            compress_observations=True,  # å‹ç¼©è§‚æµ‹èŠ‚çœå¸¦å®½
        )
    else:
        # è´¨é‡ä¼˜å…ˆ: æ›´å¤§batch,æ›´å¤šSGDè¿­ä»£
        config.rollouts(
            num_rollout_workers=max(4, num_workers // 2),
            num_envs_per_worker=1,
            rollout_fragment_length=500,
        )

    # è®­ç»ƒé…ç½®
    num_envs = config.num_rollout_workers * config.num_envs_per_worker
    fragment_length = config.rollout_fragment_length

    if algo_name.upper() == "SAC":
        # SACç‰¹å®šé…ç½®
        if optimize_for == "speed":
            train_batch_size = min(8000, num_envs * fragment_length)
        else:
            train_batch_size = min(16000, num_envs * fragment_length * 2)

        config.training(
            train_batch_size=train_batch_size,
            replay_buffer_config={
                "type": "MultiAgentReplayBuffer",
                "capacity": 100000 if optimize_for == "speed" else 1000000,
            },
            optimization={
                "actor_learning_rate": 3e-4,
                "critic_learning_rate": 3e-4,
                "entropy_learning_rate": 3e-4,
            },
            tau=0.005,
            target_network_update_freq=1,
            num_steps_sampled_before_learning_starts=1000,
        )

    elif algo_name.upper() == "PPO":
        # PPOç‰¹å®šé…ç½®
        train_batch_size = num_envs * fragment_length

        if optimize_for == "speed":
            num_sgd_iter = 5
            sgd_minibatch_size = 128
        else:
            num_sgd_iter = 10
            sgd_minibatch_size = 256

        config.training(
            train_batch_size=train_batch_size,
            sgd_minibatch_size=sgd_minibatch_size,
            num_sgd_iter=num_sgd_iter,
            lr=3e-4,
            gamma=0.99,
            lambda_=0.95,
            clip_param=0.2,
            vf_clip_param=10.0,
            entropy_coeff=0.01,
        )

    elif algo_name.upper() == "APPO":
        # APPOå¼‚æ­¥è®­ç»ƒé…ç½®
        config.training(
            train_batch_size=500,
            num_sgd_iter=1,
            lr=3e-4,
            vtrace=True,
        )

    # æ¨¡å‹é…ç½®
    config.model = {
        "fcnet_hiddens": [256, 256],
        "fcnet_activation": "relu",
        "vf_share_layers": False,
    }

    # è¯„ä¼°é…ç½®
    config.evaluation(
        evaluation_interval=10,
        evaluation_duration=10,
        evaluation_num_workers=min(2, num_workers // 4) if num_workers > 4 else 0,
        evaluation_config={
            "explore": False,
        },
    )

    # è°ƒè¯•é…ç½®
    config.debugging(
        log_level="INFO",
    )

    # æŠ¥å‘Šé…ç½®
    config.reporting(
        min_time_s_per_iteration=0,
        min_sample_timesteps_per_iteration=1000,
    )

    return config


def train_with_monitoring(
    algo,
    num_iterations: int,
    checkpoint_freq: int = 50,
    results_dir: str = "./ray_results",
):
    """
    å¸¦ç›‘æ§çš„è®­ç»ƒå¾ªç¯

    Args:
        algo: RLlibç®—æ³•å®ä¾‹
        num_iterations: è®­ç»ƒè¿­ä»£æ¬¡æ•°
        checkpoint_freq: æ£€æŸ¥ç‚¹ä¿å­˜é¢‘ç‡
        results_dir: ç»“æœä¿å­˜ç›®å½•
    """

    best_reward = -float('inf')
    start_time = time.time()

    print(f"\n{'='*70}")
    print(f"å¼€å§‹è®­ç»ƒ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*70}\n")

    for iteration in range(num_iterations):
        iter_start = time.time()

        # è®­ç»ƒä¸€æ¬¡è¿­ä»£
        result = algo.train()

        iter_time = time.time() - iter_start
        total_time = time.time() - start_time

        # æå–å…³é”®æŒ‡æ ‡
        episode_reward_mean = result.get("episode_reward_mean", 0)
        episode_len_mean = result.get("episode_len_mean", 0)
        timesteps_total = result.get("timesteps_total", 0)

        # æ€§èƒ½æŒ‡æ ‡
        info = result.get("info", {})
        learner_info = info.get("learner", {})

        # æ‰“å°è¿›åº¦
        print(f"Iteration {iteration + 1}/{num_iterations}")
        print(f"  Episode Reward Mean: {episode_reward_mean:.2f}")
        print(f"  Episode Length Mean: {episode_len_mean:.2f}")
        print(f"  Timesteps Total: {timesteps_total}")
        print(f"  Iteration Time: {iter_time:.2f}s")
        print(f"  Total Time: {total_time:.2f}s ({total_time/3600:.2f}h)")

        # é‡‡æ ·æ€§èƒ½
        sampler_results = result.get("sampler_results", {})
        if sampler_results:
            episode_reward = sampler_results.get("episode_reward_mean", 0)
            print(f"  Sampler Reward: {episode_reward:.2f}")

        # è®¡ç®—FPS
        if iter_time > 0:
            samples_per_iter = result.get("num_env_steps_sampled", 0)
            fps = samples_per_iter / iter_time
            print(f"  Sampling FPS: {fps:.0f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if episode_reward_mean > best_reward:
            best_reward = episode_reward_mean
            checkpoint_path = algo.save(results_dir)
            print(f"  ğŸ’¾ New best! Saved to: {checkpoint_path}")

        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (iteration + 1) % checkpoint_freq == 0:
            checkpoint_path = algo.save(results_dir)
            print(f"  âœ“ Checkpoint saved: {checkpoint_path}")

        print()

    # è®­ç»ƒå®Œæˆ
    total_hours = (time.time() - start_time) / 3600
    print(f"\n{'='*70}")
    print(f"è®­ç»ƒå®Œæˆ!")
    print(f"  æ€»æ—¶é—´: {total_hours:.2f}å°æ—¶")
    print(f"  æœ€ä½³å¥–åŠ±: {best_reward:.2f}")
    print(f"  æ€»é‡‡æ ·æ­¥æ•°: {timesteps_total}")
    print(f"{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(
        description="RLlibé«˜çº§è®­ç»ƒè„šæœ¬ - æ”¯æŒåˆ†å¸ƒå¼å’Œå¹¶è¡Œä¼˜åŒ–"
    )

    # ç®—æ³•å‚æ•°
    parser.add_argument("--algo", type=str, default="SAC",
                       choices=["SAC", "PPO", "APPO"],
                       help="å¼ºåŒ–å­¦ä¹ ç®—æ³•")

    # ç¯å¢ƒå‚æ•°
    parser.add_argument("--num-vessels", type=int, default=10,
                       help="èˆ¹èˆ¶æ•°é‡")
    parser.add_argument("--planning-horizon", type=int, default=7,
                       help="è§„åˆ’å‘¨æœŸ(å¤©)")
    parser.add_argument("--berth-length", type=float, default=2000.0,
                       help="æ³Šä½é•¿åº¦(ç±³)")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--iterations", type=int, default=100,
                       help="è®­ç»ƒè¿­ä»£æ¬¡æ•°")
    parser.add_argument("--checkpoint-freq", type=int, default=50,
                       help="æ£€æŸ¥ç‚¹ä¿å­˜é¢‘ç‡")

    # èµ„æºå‚æ•°
    parser.add_argument("--gpus", type=int, default=None,
                       help="GPUæ•°é‡ (None=è‡ªåŠ¨æ£€æµ‹)")
    parser.add_argument("--workers", type=int, default=None,
                       help="Workeræ•°é‡ (None=è‡ªåŠ¨è®¡ç®—)")
    parser.add_argument("--auto-resources", action="store_true",
                       help="è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€ä¼˜èµ„æºé…ç½®")

    # ä¼˜åŒ–å‚æ•°
    parser.add_argument("--optimize-for", type=str, default="speed",
                       choices=["speed", "quality"],
                       help="ä¼˜åŒ–ç›®æ ‡: speed(é€Ÿåº¦) æˆ– quality(è´¨é‡)")

    # åˆ†å¸ƒå¼å‚æ•°
    parser.add_argument("--distributed", action="store_true",
                       help="å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ (éœ€è¦Rayé›†ç¾¤)")
    parser.add_argument("--ray-address", type=str, default=None,
                       help="Rayé›†ç¾¤åœ°å€ (é»˜è®¤: æœ¬åœ°)")

    # è°ƒè¯•å‚æ•°
    parser.add_argument("--local", action="store_true",
                       help="æœ¬åœ°è°ƒè¯•æ¨¡å¼ (å•çº¿ç¨‹)")
    parser.add_argument("--profile", action="store_true",
                       help="æ€§èƒ½åˆ†ææ¨¡å¼")

    # è¾“å‡ºå‚æ•°
    parser.add_argument("--results-dir", type=str, default="./ray_results",
                       help="ç»“æœä¿å­˜ç›®å½•")
    parser.add_argument("--verbose", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    # æ˜¾ç¤ºèµ„æºä¿¡æ¯
    resources = get_optimal_resources()
    print(f"\n{'='*70}")
    print(f"ç³»ç»Ÿèµ„æºæ£€æµ‹")
    print(f"{'='*70}")
    print(f"  CPUæ ¸æ•°: {resources['num_cpus']}")
    print(f"  GPUæ•°é‡: {resources['num_gpus']}")
    print(f"  GPUå¯ç”¨: {resources['gpu_available']}")
    print(f"  æ¨èWorkeræ•°: {resources['recommended_workers']}")
    print(f"{'='*70}\n")

    # èµ„æºé…ç½®
    if args.auto_resources:
        num_gpus = resources['num_gpus'] if resources['gpu_available'] else 0
        num_workers = resources['recommended_workers']
        print(f"ğŸ¤– è‡ªåŠ¨èµ„æºé…ç½®:")
        print(f"  ä½¿ç”¨ {num_gpus} ä¸ªGPU")
        print(f"  ä½¿ç”¨ {num_workers} ä¸ªWorker\n")
    else:
        num_gpus = args.gpus if args.gpus is not None else 0
        num_workers = args.workers if args.workers is not None else 2

    # åˆå§‹åŒ–Ray
    if args.local:
        ray.init(local_mode=True, ignore_reinit_error=True)
        print("ğŸ“ æœ¬åœ°è°ƒè¯•æ¨¡å¼\n")
    elif args.distributed and args.ray_address:
        ray.init(address=args.ray_address, ignore_reinit_error=True)
        print(f"ğŸŒ å·²è¿æ¥åˆ°Rayé›†ç¾¤: {args.ray_address}\n")
    else:
        ray.init(
            num_cpus=resources['num_cpus'],
            num_gpus=resources['num_gpus'],
            ignore_reinit_error=True
        )
        print("ğŸ–¥ï¸  å•æœºæ¨¡å¼\n")

    # æ³¨å†Œç¯å¢ƒ
    register_berth_env()

    # ç¯å¢ƒé…ç½®
    env_config = {
        "num_vessels": args.num_vessels,
        "planning_horizon_days": args.planning_horizon,
        "berth_length": args.berth_length,
    }

    # åˆ›å»ºè®­ç»ƒé…ç½®
    print(f"{'='*70}")
    print(f"è®­ç»ƒé…ç½®")
    print(f"{'='*70}")
    print(f"  ç®—æ³•: {args.algo}")
    print(f"  èˆ¹èˆ¶æ•°é‡: {args.num_vessels}")
    print(f"  è§„åˆ’å‘¨æœŸ: {args.planning_horizon}å¤©")
    print(f"  æ³Šä½é•¿åº¦: {args.berth_length}ç±³")
    print(f"  è®­ç»ƒè¿­ä»£: {args.iterations}")
    print(f"  GPUæ•°é‡: {num_gpus}")
    print(f"  Workeræ•°é‡: {num_workers}")
    print(f"  ä¼˜åŒ–ç›®æ ‡: {args.optimize_for}")
    print(f"  åˆ†å¸ƒå¼: {args.distributed}")
    print(f"  ç»“æœç›®å½•: {args.results_dir}")
    print(f"{'='*70}\n")

    config = create_training_config(
        algo_name=args.algo,
        env_config=env_config,
        num_gpus=num_gpus,
        num_workers=num_workers,
        distributed=args.distributed,
        optimize_for=args.optimize_for,
    )

    # åˆ›å»ºç®—æ³•å®ä¾‹
    algo = config.build()

    # æ€§èƒ½åˆ†ææ¨¡å¼
    if args.profile:
        import cProfile
        profiler = cProfile.Profile()
        profiler.enable()

    try:
        # è®­ç»ƒ
        train_with_monitoring(
            algo=algo,
            num_iterations=args.iterations,
            checkpoint_freq=args.checkpoint_freq,
            results_dir=args.results_dir,
        )

    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ€§èƒ½åˆ†æ
        if args.profile:
            profiler.disable()
            profiler.print_stats(sort='cumtime')

        # æ¸…ç†
        algo.stop()
        ray.shutdown()

        print("\nâœ… è®­ç»ƒç»“æŸï¼Œèµ„æºå·²é‡Šæ”¾\n")


if __name__ == "__main__":
    main()
